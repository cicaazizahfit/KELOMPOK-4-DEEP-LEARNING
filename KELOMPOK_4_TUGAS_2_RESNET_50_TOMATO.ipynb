{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KELOMPOK 4 TUGAS 2 RESNET 50 TOMATO.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "doE6m1OiuRKY",
        "colab_type": "code",
        "outputId": "c40c9bdb-e86a-43a7-fee5-c85aa96ad66a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.python.keras.applications import ResNet50\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras_applications.resnet import preprocess_input\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "resnet_weights_path = '/content/drive/My Drive/dataset/lambace/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymp65NPpEFnY",
        "colab_type": "code",
        "outputId": "cdcba4bc-8161-445a-c92d-ad9c0fa353f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "#from resnets_utils import *\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ95E-mFxTaP",
        "colab_type": "code",
        "outputId": "12dd2d44-3f40-4a1e-f0bc-87563f379491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9_susboxV54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "default_image_size = tuple((224, 224))\n",
        "image_size = 0\n",
        "directory_root = '/content/drive/My Drive/dataset'\n",
        "width=224\n",
        "height=224\n",
        "depth=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkLlsJY-xXQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIANL3-IxZvv",
        "colab_type": "code",
        "outputId": "351e05ca-87e0-4213-ad0c-a7944fb671ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # remove .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for plant_folder in root_dir :\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
        "        \n",
        "        for disease_folder in plant_disease_folder_list :\n",
        "            # remove .DS_Store from list\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "\n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}\")\n",
        "                \n",
        "            for single_plant_disease_image in plant_disease_image_list :\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "\n",
        "            for image in plant_disease_image_list[:200]:\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] Processing Tomato___Bacterial_spot ...\n",
            "[INFO] Processing Tomato___Leaf_Mold ...\n",
            "[INFO] Processing Tomato___Tomato_Yellow_Leaf_Curl_Virus ...\n",
            "[INFO] Processing Tomato___Early_blight ...\n",
            "[INFO] Processing Tomato___Late_blight ...\n",
            "[INFO] Processing Tomato___Septoria_leaf_spot ...\n",
            "[INFO] Processing Tomato___Bacterial_spot ...\n",
            "[INFO] Processing Tomato___Early_blight ...\n",
            "[INFO] Processing Tomato___Late_blight ...\n",
            "[INFO] Processing Tomato___Leaf_Mold ...\n",
            "[INFO] Processing Tomato___Septoria_leaf_spot ...\n",
            "[INFO] Processing Tomato___Tomato_Yellow_Leaf_Curl_Virus ...\n",
            "[INFO] Processing 01 Whole Beans ...\n",
            "[INFO] Processing 02 Broken Beans ...\n",
            "[INFO] Processing 03 Bean Fraction ...\n",
            "[INFO] Processing 04 Skin Damaged ...\n",
            "[INFO] Processing 05 Fermented ...\n",
            "[INFO] Processing 06 Unfermented ...\n",
            "[INFO] Processing 07 Moldy ...\n",
            "[INFO] Image loading completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBsRpxj9M_HH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = len(image_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8nR0KeUxgGB",
        "colab_type": "code",
        "outputId": "1a33957f-ef1f-4ccb-fa64-6654cec0e89b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(image_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN-zFfL52_Jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEkUEga83l98",
        "colab_type": "code",
        "outputId": "32f1150e-f097-4963-a547-4bf7b52923cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['01 Whole Beans' '02 Broken Beans' '03 Bean Fraction' '04 Skin Damaged'\n",
            " '05 Fermented' '06 Unfermented' '07 Moldy' 'Tomato___Bacterial_spot'\n",
            " 'Tomato___Early_blight' 'Tomato___Late_blight' 'Tomato___Leaf_Mold'\n",
            " 'Tomato___Septoria_leaf_spot' 'Tomato___Tomato_Yellow_Leaf_Curl_Virus']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZtZbsgv3wmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV8iuz6SxlGz",
        "colab_type": "code",
        "outputId": "08abbe85-c30d-4543-b112-28c40e06c88a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"[INFO] Spliting data to train, test\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Spliting data to train, test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fyAdsIIxmJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, \n",
        "    zoom_range=0.2,horizontal_flip=True, \n",
        "    fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTUxd2si_KXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: identity_block\n",
        "\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 3\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    \n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(F2,kernel_size=(f,f),strides=(1,1),padding='same',kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=-1)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(F3,(1,1),strides=(1,1),padding='valid',kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=-1)(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X,X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C5vkl8N5LRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbLvi9nWDQx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(filters =F1, kernel_size =(1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters =F2, kernel_size =(f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters =F3, kernel_size =(1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### (≈2 lines)\n",
        "    X_shortcut = Conv2D(filters =F3, kernel_size =(1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut]) \n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfTR3VBKxrHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: ResNet50\n",
        "\n",
        "def ResNet50(input_shape = (64, 64, 3), classes = 13):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D(pool_size=(2, 2), name = 'avg_pool')(X)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e0fe893a-0f9f-4128-cf05-117b0111d765",
        "id": "1zKgwDZb6E08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "model = ResNet50(input_shape = (224, 224, 3), classes = 13)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbSxpmAQxv6J",
        "colab_type": "code",
        "outputId": "de1e8a36-7a6c-4903-aa15-014ac3c0e5fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a47N4duu6lIb",
        "colab_type": "code",
        "outputId": "dcf3a269-4f5d-4264-f950-bf01d77f0d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 55, 55, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 55, 55, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 55, 55, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 55, 55, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 55, 55, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 55, 55, 256)  0           batch_normalization_2[0][0]      \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 55, 55, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 55, 55, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 55, 55, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 55, 55, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 55, 55, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 55, 55, 256)  0           batch_normalization_4[0][0]      \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 55, 55, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 28, 28, 128)  512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 28, 28, 512)  2048        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_6[0][0]      \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 28, 28, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 28, 28, 512)  2048        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_8[0][0]      \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 28, 28, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 28, 28, 512)  2048        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           batch_normalization_10[0][0]     \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 14, 14, 256)  1024        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 14, 14, 1024) 4096        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_12[0][0]     \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 14, 14, 256)  1024        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 14, 14, 1024) 4096        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_14[0][0]     \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 14, 14, 256)  1024        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 14, 14, 1024) 4096        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_16[0][0]     \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 14, 14, 256)  1024        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 14, 14, 1024) 4096        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_18[0][0]     \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 14, 14, 256)  1024        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 14, 14, 1024) 4096        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_20[0][0]     \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 7, 7, 512)    2048        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 7, 7, 2048)   8192        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_22[0][0]     \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 7, 7, 512)    2048        conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 7, 7, 2048)   8192        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_24[0][0]     \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 2048)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 18432)        0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc13 (Dense)                    (None, 13)           239629      flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,827,341\n",
            "Trainable params: 23,774,221\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-oijktZ6uKR",
        "colab_type": "code",
        "outputId": "c482c9c9-2da7-4252-e06a-2fa68853ca54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train model\n",
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    verbose=1\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/100\n",
            "61/61 [==============================] - 42s 682ms/step - loss: 0.3911 - acc: 0.9175 - val_loss: 0.2953 - val_acc: 0.9287\n",
            "Epoch 2/100\n",
            "61/61 [==============================] - 26s 420ms/step - loss: 0.3149 - acc: 0.9232 - val_loss: 0.3102 - val_acc: 0.9208\n",
            "Epoch 3/100\n",
            "61/61 [==============================] - 26s 419ms/step - loss: 0.2730 - acc: 0.9283 - val_loss: 0.2670 - val_acc: 0.9294\n",
            "Epoch 4/100\n",
            "61/61 [==============================] - 25s 417ms/step - loss: 0.2268 - acc: 0.9345 - val_loss: 0.2859 - val_acc: 0.9350\n",
            "Epoch 5/100\n",
            "61/61 [==============================] - 25s 408ms/step - loss: 0.2178 - acc: 0.9332 - val_loss: 0.1697 - val_acc: 0.9394\n",
            "Epoch 6/100\n",
            "61/61 [==============================] - 25s 407ms/step - loss: 0.1821 - acc: 0.9395 - val_loss: 0.1482 - val_acc: 0.9459\n",
            "Epoch 7/100\n",
            "61/61 [==============================] - 25s 405ms/step - loss: 0.1443 - acc: 0.9467 - val_loss: 0.1364 - val_acc: 0.9498\n",
            "Epoch 8/100\n",
            "61/61 [==============================] - 25s 410ms/step - loss: 0.1394 - acc: 0.9503 - val_loss: 0.1170 - val_acc: 0.9587\n",
            "Epoch 9/100\n",
            "61/61 [==============================] - 25s 407ms/step - loss: 0.1363 - acc: 0.9519 - val_loss: 0.1831 - val_acc: 0.9501\n",
            "Epoch 10/100\n",
            "61/61 [==============================] - 25s 407ms/step - loss: 0.2564 - acc: 0.9313 - val_loss: 0.1798 - val_acc: 0.9394\n",
            "Epoch 11/100\n",
            "61/61 [==============================] - 25s 410ms/step - loss: 0.1631 - acc: 0.9436 - val_loss: 0.1495 - val_acc: 0.9529\n",
            "Epoch 12/100\n",
            "61/61 [==============================] - 25s 409ms/step - loss: 0.1863 - acc: 0.9434 - val_loss: 0.1434 - val_acc: 0.9563\n",
            "Epoch 13/100\n",
            "61/61 [==============================] - 25s 408ms/step - loss: 0.2448 - acc: 0.9391 - val_loss: 0.2639 - val_acc: 0.9392\n",
            "Epoch 14/100\n",
            "61/61 [==============================] - 25s 409ms/step - loss: 0.2298 - acc: 0.9425 - val_loss: 0.2033 - val_acc: 0.9487\n",
            "Epoch 15/100\n",
            "61/61 [==============================] - 25s 403ms/step - loss: 0.2028 - acc: 0.9490 - val_loss: 0.2012 - val_acc: 0.9527\n",
            "Epoch 16/100\n",
            "61/61 [==============================] - 25s 405ms/step - loss: 0.1918 - acc: 0.9506 - val_loss: 0.1850 - val_acc: 0.9508\n",
            "Epoch 17/100\n",
            "61/61 [==============================] - 25s 411ms/step - loss: 0.1825 - acc: 0.9518 - val_loss: 0.1874 - val_acc: 0.9484\n",
            "Epoch 18/100\n",
            "61/61 [==============================] - 25s 411ms/step - loss: 0.2178 - acc: 0.9405 - val_loss: 0.2415 - val_acc: 0.9322\n",
            "Epoch 19/100\n",
            "61/61 [==============================] - 25s 408ms/step - loss: 0.2403 - acc: 0.9386 - val_loss: 0.2728 - val_acc: 0.9330\n",
            "Epoch 20/100\n",
            "61/61 [==============================] - 25s 409ms/step - loss: 0.2328 - acc: 0.9410 - val_loss: 0.2316 - val_acc: 0.9493\n",
            "Epoch 21/100\n",
            "61/61 [==============================] - 25s 411ms/step - loss: 0.2182 - acc: 0.9479 - val_loss: 0.2104 - val_acc: 0.9490\n",
            "Epoch 22/100\n",
            "61/61 [==============================] - 25s 410ms/step - loss: 0.1756 - acc: 0.9516 - val_loss: 0.1213 - val_acc: 0.9650\n",
            "Epoch 23/100\n",
            "61/61 [==============================] - 25s 407ms/step - loss: 0.1656 - acc: 0.9512 - val_loss: 0.1500 - val_acc: 0.9580\n",
            "Epoch 24/100\n",
            "61/61 [==============================] - 25s 411ms/step - loss: 0.1479 - acc: 0.9519 - val_loss: 0.1238 - val_acc: 0.9612\n",
            "Epoch 25/100\n",
            "61/61 [==============================] - 25s 406ms/step - loss: 0.1419 - acc: 0.9540 - val_loss: 0.1157 - val_acc: 0.9634\n",
            "Epoch 26/100\n",
            "61/61 [==============================] - 25s 410ms/step - loss: 0.1555 - acc: 0.9548 - val_loss: 0.1137 - val_acc: 0.9580\n",
            "Epoch 27/100\n",
            "61/61 [==============================] - 25s 410ms/step - loss: 0.1364 - acc: 0.9546 - val_loss: 0.1346 - val_acc: 0.9539\n",
            "Epoch 28/100\n",
            "61/61 [==============================] - 25s 403ms/step - loss: 0.1232 - acc: 0.9556 - val_loss: 0.1074 - val_acc: 0.9656\n",
            "Epoch 29/100\n",
            "61/61 [==============================] - 25s 406ms/step - loss: 0.1239 - acc: 0.9612 - val_loss: 0.1180 - val_acc: 0.9595\n",
            "Epoch 30/100\n",
            "61/61 [==============================] - 25s 404ms/step - loss: 0.1158 - acc: 0.9611 - val_loss: 0.1049 - val_acc: 0.9670\n",
            "Epoch 31/100\n",
            "61/61 [==============================] - 24s 400ms/step - loss: 0.1014 - acc: 0.9670 - val_loss: 0.0850 - val_acc: 0.9713\n",
            "Epoch 32/100\n",
            "61/61 [==============================] - 24s 399ms/step - loss: 0.0929 - acc: 0.9687 - val_loss: 0.0898 - val_acc: 0.9736\n",
            "Epoch 33/100\n",
            "61/61 [==============================] - 24s 400ms/step - loss: 0.0977 - acc: 0.9675 - val_loss: 0.1048 - val_acc: 0.9699\n",
            "Epoch 34/100\n",
            "61/61 [==============================] - 24s 401ms/step - loss: 0.0859 - acc: 0.9705 - val_loss: 0.0855 - val_acc: 0.9716\n",
            "Epoch 35/100\n",
            "61/61 [==============================] - 25s 403ms/step - loss: 0.0977 - acc: 0.9675 - val_loss: 0.0697 - val_acc: 0.9763\n",
            "Epoch 36/100\n",
            "61/61 [==============================] - 25s 403ms/step - loss: 0.0784 - acc: 0.9706 - val_loss: 0.0725 - val_acc: 0.9724\n",
            "Epoch 37/100\n",
            "61/61 [==============================] - 25s 406ms/step - loss: 0.0865 - acc: 0.9710 - val_loss: 0.0896 - val_acc: 0.9707\n",
            "Epoch 38/100\n",
            "61/61 [==============================] - 24s 402ms/step - loss: 0.1311 - acc: 0.9671 - val_loss: 0.1368 - val_acc: 0.9707\n",
            "Epoch 39/100\n",
            "61/61 [==============================] - 25s 405ms/step - loss: 0.1069 - acc: 0.9715 - val_loss: 0.0944 - val_acc: 0.9741\n",
            "Epoch 40/100\n",
            "61/61 [==============================] - 25s 409ms/step - loss: 0.0935 - acc: 0.9705 - val_loss: 0.0704 - val_acc: 0.9774\n",
            "Epoch 41/100\n",
            "61/61 [==============================] - 25s 405ms/step - loss: 0.0826 - acc: 0.9705 - val_loss: 0.0844 - val_acc: 0.9729\n",
            "Epoch 42/100\n",
            "61/61 [==============================] - 24s 401ms/step - loss: 0.0820 - acc: 0.9707 - val_loss: 0.0865 - val_acc: 0.9729\n",
            "Epoch 43/100\n",
            "61/61 [==============================] - 25s 404ms/step - loss: 0.0931 - acc: 0.9708 - val_loss: 0.0869 - val_acc: 0.9722\n",
            "Epoch 44/100\n",
            "61/61 [==============================] - 24s 399ms/step - loss: 0.0717 - acc: 0.9734 - val_loss: 0.0773 - val_acc: 0.9749\n",
            "Epoch 45/100\n",
            "61/61 [==============================] - 24s 399ms/step - loss: 0.0763 - acc: 0.9726 - val_loss: 0.0825 - val_acc: 0.9724\n",
            "Epoch 46/100\n",
            "61/61 [==============================] - 24s 396ms/step - loss: 0.0654 - acc: 0.9770 - val_loss: 0.0572 - val_acc: 0.9778\n",
            "Epoch 47/100\n",
            "61/61 [==============================] - 24s 401ms/step - loss: 0.0591 - acc: 0.9780 - val_loss: 0.0508 - val_acc: 0.9809\n",
            "Epoch 48/100\n",
            "61/61 [==============================] - 25s 405ms/step - loss: 0.0586 - acc: 0.9788 - val_loss: 0.0483 - val_acc: 0.9814\n",
            "Epoch 49/100\n",
            "61/61 [==============================] - 25s 408ms/step - loss: 0.0518 - acc: 0.9806 - val_loss: 0.0502 - val_acc: 0.9806\n",
            "Epoch 50/100\n",
            "61/61 [==============================] - 25s 404ms/step - loss: 0.0574 - acc: 0.9796 - val_loss: 0.0493 - val_acc: 0.9825\n",
            "Epoch 51/100\n",
            "61/61 [==============================] - 25s 407ms/step - loss: 0.0524 - acc: 0.9809 - val_loss: 0.0585 - val_acc: 0.9809\n",
            "Epoch 52/100\n",
            "61/61 [==============================] - 25s 403ms/step - loss: 0.0500 - acc: 0.9815 - val_loss: 0.0514 - val_acc: 0.9808\n",
            "Epoch 53/100\n",
            "61/61 [==============================] - 25s 404ms/step - loss: 0.0463 - acc: 0.9823 - val_loss: 0.0461 - val_acc: 0.9823\n",
            "Epoch 54/100\n",
            "61/61 [==============================] - 25s 407ms/step - loss: 0.0495 - acc: 0.9816 - val_loss: 0.0452 - val_acc: 0.9822\n",
            "Epoch 55/100\n",
            "61/61 [==============================] - 25s 405ms/step - loss: 0.0407 - acc: 0.9839 - val_loss: 0.0426 - val_acc: 0.9822\n",
            "Epoch 56/100\n",
            "61/61 [==============================] - 25s 404ms/step - loss: 0.0461 - acc: 0.9828 - val_loss: 0.0490 - val_acc: 0.9789\n",
            "Epoch 57/100\n",
            "61/61 [==============================] - 25s 406ms/step - loss: 0.0488 - acc: 0.9800 - val_loss: 0.0387 - val_acc: 0.9820\n",
            "Epoch 58/100\n",
            "61/61 [==============================] - 25s 403ms/step - loss: 0.0343 - acc: 0.9858 - val_loss: 0.0411 - val_acc: 0.9825\n",
            "Epoch 59/100\n",
            "61/61 [==============================] - 25s 405ms/step - loss: 0.0458 - acc: 0.9826 - val_loss: 0.0418 - val_acc: 0.9846\n",
            "Epoch 60/100\n",
            "61/61 [==============================] - 25s 412ms/step - loss: 0.0389 - acc: 0.9850 - val_loss: 0.0346 - val_acc: 0.9859\n",
            "Epoch 61/100\n",
            "61/61 [==============================] - 25s 407ms/step - loss: 0.0359 - acc: 0.9869 - val_loss: 0.0387 - val_acc: 0.9833\n",
            "Epoch 62/100\n",
            "61/61 [==============================] - 25s 403ms/step - loss: 0.0376 - acc: 0.9853 - val_loss: 0.0342 - val_acc: 0.9868\n",
            "Epoch 63/100\n",
            "61/61 [==============================] - 25s 402ms/step - loss: 0.0329 - acc: 0.9875 - val_loss: 0.0357 - val_acc: 0.9837\n",
            "Epoch 64/100\n",
            "61/61 [==============================] - 25s 415ms/step - loss: 0.0306 - acc: 0.9881 - val_loss: 0.0315 - val_acc: 0.9865\n",
            "Epoch 65/100\n",
            "61/61 [==============================] - 25s 408ms/step - loss: 0.0286 - acc: 0.9884 - val_loss: 0.0346 - val_acc: 0.9867\n",
            "Epoch 66/100\n",
            "61/61 [==============================] - 25s 407ms/step - loss: 0.0292 - acc: 0.9887 - val_loss: 0.0394 - val_acc: 0.9822\n",
            "Epoch 67/100\n",
            "61/61 [==============================] - 25s 404ms/step - loss: 0.0374 - acc: 0.9856 - val_loss: 0.0337 - val_acc: 0.9860\n",
            "Epoch 68/100\n",
            "61/61 [==============================] - 24s 399ms/step - loss: 0.0291 - acc: 0.9877 - val_loss: 0.0370 - val_acc: 0.9837\n",
            "Epoch 69/100\n",
            "61/61 [==============================] - 24s 398ms/step - loss: 0.0306 - acc: 0.9877 - val_loss: 0.0392 - val_acc: 0.9839\n",
            "Epoch 70/100\n",
            "61/61 [==============================] - 25s 404ms/step - loss: 0.0337 - acc: 0.9853 - val_loss: 0.0307 - val_acc: 0.9874\n",
            "Epoch 71/100\n",
            "61/61 [==============================] - 25s 403ms/step - loss: 0.0306 - acc: 0.9874 - val_loss: 0.0388 - val_acc: 0.9836\n",
            "Epoch 72/100\n",
            "61/61 [==============================] - 24s 397ms/step - loss: 0.0299 - acc: 0.9880 - val_loss: 0.0438 - val_acc: 0.9842\n",
            "Epoch 73/100\n",
            "61/61 [==============================] - 25s 417ms/step - loss: 0.0304 - acc: 0.9882 - val_loss: 0.0310 - val_acc: 0.9882\n",
            "Epoch 74/100\n",
            "61/61 [==============================] - 25s 405ms/step - loss: 0.0298 - acc: 0.9881 - val_loss: 0.0264 - val_acc: 0.9888\n",
            "Epoch 75/100\n",
            "61/61 [==============================] - 25s 405ms/step - loss: 0.0288 - acc: 0.9887 - val_loss: 0.0303 - val_acc: 0.9862\n",
            "Epoch 76/100\n",
            "61/61 [==============================] - 25s 408ms/step - loss: 0.0263 - acc: 0.9896 - val_loss: 0.0292 - val_acc: 0.9891\n",
            "Epoch 77/100\n",
            "61/61 [==============================] - 24s 401ms/step - loss: 0.0281 - acc: 0.9893 - val_loss: 0.0304 - val_acc: 0.9887\n",
            "Epoch 78/100\n",
            "61/61 [==============================] - 25s 403ms/step - loss: 0.0288 - acc: 0.9888 - val_loss: 0.0346 - val_acc: 0.9857\n",
            "Epoch 79/100\n",
            "61/61 [==============================] - 25s 404ms/step - loss: 0.0277 - acc: 0.9891 - val_loss: 0.0327 - val_acc: 0.9859\n",
            "Epoch 80/100\n",
            "61/61 [==============================] - 24s 400ms/step - loss: 0.0284 - acc: 0.9887 - val_loss: 0.0255 - val_acc: 0.9895\n",
            "Epoch 81/100\n",
            "61/61 [==============================] - 24s 397ms/step - loss: 0.0255 - acc: 0.9900 - val_loss: 0.0314 - val_acc: 0.9879\n",
            "Epoch 82/100\n",
            "61/61 [==============================] - 24s 401ms/step - loss: 0.0283 - acc: 0.9887 - val_loss: 0.0346 - val_acc: 0.9873\n",
            "Epoch 83/100\n",
            "61/61 [==============================] - 25s 404ms/step - loss: 0.0282 - acc: 0.9893 - val_loss: 0.0336 - val_acc: 0.9860\n",
            "Epoch 84/100\n",
            "61/61 [==============================] - 25s 403ms/step - loss: 0.0227 - acc: 0.9908 - val_loss: 0.0247 - val_acc: 0.9901\n",
            "Epoch 85/100\n",
            "61/61 [==============================] - 25s 407ms/step - loss: 0.0251 - acc: 0.9898 - val_loss: 0.0327 - val_acc: 0.9873\n",
            "Epoch 86/100\n",
            "61/61 [==============================] - 24s 401ms/step - loss: 0.0277 - acc: 0.9886 - val_loss: 0.0367 - val_acc: 0.9864\n",
            "Epoch 87/100\n",
            "61/61 [==============================] - 24s 399ms/step - loss: 0.0266 - acc: 0.9898 - val_loss: 0.0315 - val_acc: 0.9859\n",
            "Epoch 88/100\n",
            "61/61 [==============================] - 25s 405ms/step - loss: 0.0216 - acc: 0.9916 - val_loss: 0.0318 - val_acc: 0.9871\n",
            "Epoch 89/100\n",
            "61/61 [==============================] - 25s 405ms/step - loss: 0.0327 - acc: 0.9869 - val_loss: 0.0340 - val_acc: 0.9864\n",
            "Epoch 90/100\n",
            "61/61 [==============================] - 25s 403ms/step - loss: 0.0265 - acc: 0.9901 - val_loss: 0.0305 - val_acc: 0.9884\n",
            "Epoch 91/100\n",
            "61/61 [==============================] - 25s 407ms/step - loss: 0.0235 - acc: 0.9899 - val_loss: 0.0308 - val_acc: 0.9879\n",
            "Epoch 92/100\n",
            "61/61 [==============================] - 25s 409ms/step - loss: 0.0276 - acc: 0.9894 - val_loss: 0.0311 - val_acc: 0.9867\n",
            "Epoch 93/100\n",
            "61/61 [==============================] - 25s 404ms/step - loss: 0.0257 - acc: 0.9902 - val_loss: 0.0230 - val_acc: 0.9898\n",
            "Epoch 94/100\n",
            "61/61 [==============================] - 24s 401ms/step - loss: 0.0206 - acc: 0.9913 - val_loss: 0.0237 - val_acc: 0.9893\n",
            "Epoch 95/100\n",
            "61/61 [==============================] - 25s 403ms/step - loss: 0.0174 - acc: 0.9930 - val_loss: 0.0325 - val_acc: 0.9882\n",
            "Epoch 96/100\n",
            "61/61 [==============================] - 25s 403ms/step - loss: 0.0309 - acc: 0.9873 - val_loss: 0.0262 - val_acc: 0.9887\n",
            "Epoch 97/100\n",
            "61/61 [==============================] - 25s 404ms/step - loss: 0.0189 - acc: 0.9921 - val_loss: 0.0342 - val_acc: 0.9882\n",
            "Epoch 98/100\n",
            "61/61 [==============================] - 25s 404ms/step - loss: 0.0229 - acc: 0.9904 - val_loss: 0.0233 - val_acc: 0.9905\n",
            "Epoch 99/100\n",
            "61/61 [==============================] - 25s 404ms/step - loss: 0.0218 - acc: 0.9911 - val_loss: 0.0280 - val_acc: 0.9895\n",
            "Epoch 100/100\n",
            "61/61 [==============================] - 24s 401ms/step - loss: 0.0213 - acc: 0.9916 - val_loss: 0.0353 - val_acc: 0.9874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfyiynlJIqyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fdgPyH_A3Ih",
        "colab_type": "code",
        "outputId": "f15d915c-ec27-44fe-f59b-b648a407afd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1briDNlTObWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S3jeQ1POc4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V-7LeevKMJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAe4R-Xd0FxB",
        "colab_type": "code",
        "outputId": "922be005-7670-4a44-b4ae-f33932ac15b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Calculating model accuracy\n",
            "496/496 [==============================] - 1s 3ms/step\n",
            "Test Accuracy: 98.7437944258413\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}